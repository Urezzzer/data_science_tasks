{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-59d8e019b502>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mauto\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmetrics\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mtensorflow\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodels\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mload_model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapplications\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mEfficientNetV2B2\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtyping\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_typing\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 37\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtools\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmodule_util\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_module_util\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     38\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutil\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlazy_loader\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mLazyLoader\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0m_LazyLoader\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     43\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mdistribute\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[1;31m# from tensorflow.python import keras\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 45\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature_column\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mfeature_column_lib\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mfeature_column\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     46\u001B[0m \u001B[1;31m# from tensorflow.python.layers import layers\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodule\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmodule\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column_lib.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;31m# pylint: disable=unused-import,line-too-long,wildcard-import,g-bad-import-order\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature_column\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature_column\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature_column\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature_column_v2\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfeature_column\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msequence_feature_column\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m    141\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msparse_tensor\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0msparse_tensor_lib\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    142\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtensor_shape\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 143\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mbase\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    144\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    145\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcheck_ops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;31m# =============================================================================\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;34m\"\"\"Contains the base Layer class, from which all layers inherit.\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlegacy_tf_layers\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mbase\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[0mInputSpec\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbase\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mInputSpec\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[1;31m# See b/110718070#comment18 for more details about this import.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 25\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmodels\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     26\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minput_layer\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mInput\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\models.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mframework\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mbackend\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mmetrics\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mmetrics_module\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mkeras\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0moptimizer_v1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     70\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0msparse_ops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mstate_ops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 72\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtensor_array_grad\u001B[0m  \u001B[1;31m# pylint: disable=unused-import\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     73\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtensor_array_ops\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpython\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mops\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mvariables\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mvariables_module\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_array_grad.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     20\u001B[0m \u001B[1;31m# TODO(b/31222613): These ops may be differentiable, and there may be\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;31m# latent bugs here.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 22\u001B[1;33m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNotDifferentiable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"TensorArray\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     23\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNotDifferentiable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"TensorArrayGrad\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mNotDifferentiable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"TensorArraySize\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001B[0m in \u001B[0;36mno_gradient\u001B[1;34m(op_type)\u001B[0m\n\u001B[0;32m   2815\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mop_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msix\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstring_types\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2816\u001B[0m     \u001B[1;32mraise\u001B[0m \u001B[0mTypeError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"op_type must be a string\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2817\u001B[1;33m   \u001B[0mgradient_registry\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mregister\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mop_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2818\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2819\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\registry.py\u001B[0m in \u001B[0;36mregister\u001B[1;34m(self, candidate, name)\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[1;31m# stack trace is [this_function, Register(), user_function,...]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m     \u001B[1;31m# so the user function is #2.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 65\u001B[1;33m     \u001B[0mstack\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtraceback\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextract_stack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlimit\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m3\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     66\u001B[0m     \u001B[0mstack_index\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstack\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     67\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mstack_index\u001B[0m \u001B[1;33m>=\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\traceback.py\u001B[0m in \u001B[0;36mextract_stack\u001B[1;34m(f, limit)\u001B[0m\n\u001B[0;32m    209\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mf\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m         \u001B[0mf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msys\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_getframe\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf_back\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 211\u001B[1;33m     \u001B[0mstack\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mStackSummary\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mextract\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mwalk_stack\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlimit\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlimit\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    212\u001B[0m     \u001B[0mstack\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreverse\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    213\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mstack\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\traceback.py\u001B[0m in \u001B[0;36mextract\u001B[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001B[0m\n\u001B[0;32m    364\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlookup_lines\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    365\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mf\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 366\u001B[1;33m                 \u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mline\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    367\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    368\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\traceback.py\u001B[0m in \u001B[0;36mline\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    286\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mline\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    287\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_line\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 288\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_line\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlinecache\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgetline\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlineno\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    289\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_line\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    290\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\linecache.py\u001B[0m in \u001B[0;36mgetline\u001B[1;34m(filename, lineno, module_globals)\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mgetline\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlineno\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodule_globals\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 16\u001B[1;33m     \u001B[0mlines\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mgetlines\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodule_globals\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     17\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[1;36m1\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[0mlineno\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlines\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mlines\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mlineno\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\linecache.py\u001B[0m in \u001B[0;36mgetlines\u001B[1;34m(filename, module_globals)\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     46\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 47\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mupdatecache\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmodule_globals\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     48\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mMemoryError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     49\u001B[0m         \u001B[0mclearcache\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\linecache.py\u001B[0m in \u001B[0;36mupdatecache\u001B[1;34m(filename, module_globals)\u001B[0m\n\u001B[0;32m    134\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    135\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 136\u001B[1;33m         \u001B[1;32mwith\u001B[0m \u001B[0mtokenize\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mopen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfullname\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mfp\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    137\u001B[0m             \u001B[0mlines\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreadlines\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    138\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mOSError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\strix\\appdata\\local\\programs\\python\\python38\\lib\\tokenize.py\u001B[0m in \u001B[0;36mopen\u001B[1;34m(filename)\u001B[0m\n\u001B[0;32m    390\u001B[0m     \u001B[0mdetect_encoding\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    391\u001B[0m     \"\"\"\n\u001B[1;32m--> 392\u001B[1;33m     \u001B[0mbuffer\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_builtin_open\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'rb'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    393\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    394\u001B[0m         \u001B[0mencoding\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlines\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdetect_encoding\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbuffer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreadline\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.applications import EfficientNetV2B2\n",
    "from tensorflow.keras.applications.efficientnet_v2 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import collections\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import time\n",
    "import random\n",
    "from keras import backend as K\n",
    "import pathlib\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "seed_everything(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_captions = pd.read_csv('data/train.csv')\n",
    "train_captions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка фотографий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('data/train/groups') # необходимо разархивировать архив\n",
    "image_paths = list(data_dir.glob('*/*.png'))\n",
    "image_count = len(image_paths)\n",
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(str(image_paths[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "img_height = 240\n",
    "img_width = 240\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  seed=seed,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=seed,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "class_names = train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\n",
    "    mode='horizontal_and_vertical',\n",
    "    seed=seed\n",
    "    ),\n",
    "  tf.keras.layers.RandomRotation(\n",
    "    factor=(-0.1, 0.1),\n",
    "    seed=seed,\n",
    "    fill_mode='constant',\n",
    "    fill_value=255\n",
    "    ),\n",
    "  tf.keras.layers.RandomZoom(\n",
    "    height_factor=(-0.1, 0.1),\n",
    "    seed=seed,\n",
    "    ),\n",
    "  tf.keras.layers.RandomBrightness(\n",
    "      factor=(-0.2, 0.2),\n",
    "      seed=seed),\n",
    "    tf.keras.layers.RandomContrast(\n",
    "      factor=(0., 0.2), \n",
    "      seed=seed\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    augmented_images = data_augmentation(images, training=True)\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot / categorical encoding\n",
    "def input_preprocess(image, label):\n",
    "    label = tf.one_hot(label, n_classes)\n",
    "    image = data_augmentation(image, training=True)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(\n",
    "    input_preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
    ")\n",
    "val_ds = val_ds.map(\n",
    "    input_preprocess, num_parallel_calls=tf.data.AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модель-Классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(num_classes):\n",
    "    inputs = tf.keras.layers.Input(shape=(img_height, img_width, 3))\n",
    "    model = EfficientNetV2B2(include_top=False, input_tensor=inputs, weights=\"imagenet\")\n",
    "    \n",
    "    # Freeze the pretrained weights\n",
    "    model.trainable = False\n",
    "\n",
    "    # Rebuild top\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = tf.keras.layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "\n",
    "    # Compile\n",
    "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(num_classes=n_classes)\n",
    "model.summary(\n",
    "    show_trainable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 8\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfreeze_model(model, n_layers):\n",
    "    # We unfreeze the top n layers while leaving BatchNorm layers frozen\n",
    "    for layer in model.layers[-n_layers:]:\n",
    "        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "unfreeze_model(model, 10)\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "unfreeze_model(model, 20)\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "unfreeze_model(model, 30)\n",
    "model.fit(train_ds, epochs=epochs, validation_data=val_ds, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('weights/EfficientNetV2B2_v7.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тестирование модели (Поиск схожих картинок)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = load_model('weights/EfficientNetV2B2_v7.h5')\n",
    "# Customize the model to return features from fully-connected layer\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('avg_pool').output)\n",
    "model.trainable = False\n",
    "\n",
    "model.summary(\n",
    "    show_trainable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "def extract_features(path, model=model):\n",
    "    img = cv2.imread(path)\n",
    "    img = tf.keras.layers.Resizing(240, 240)(img)\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "\n",
    "    feature = model.predict(x, verbose=0)[0]\n",
    "\n",
    "    return feature / np.linalg.norm(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = []\n",
    "\n",
    "for idx in tqdm(train_captions.idx):\n",
    "    train_embeddings.append(extract_features(f'data/train/{idx}.png'))\n",
    "\n",
    "train_embeddings = np.array(train_embeddings)\n",
    "\n",
    "queries_embeddings = []\n",
    "\n",
    "for idx in tqdm(train_captions.idx[1000:1300]):\n",
    "    queries_embeddings.append(extract_features(f'data/train/{idx}.png'))\n",
    "\n",
    "queries_embeddings = np.array(queries_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "\n",
    "mapper = PCA(n_components=1000)\n",
    "mapper.fit(train_embeddings)\n",
    "\n",
    "exp_var_pca = mapper.explained_variance_ratio_\n",
    "#\n",
    "# Cumulative sum of eigenvalues; This will be used to create step plot\n",
    "# for visualizing the variance explained by each principal component.\n",
    "#\n",
    "cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "#\n",
    "# Create the visualization plot\n",
    "#\n",
    "plt.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "plt.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal component index')\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mapper = KernelPCA(n_components=400, kernel='rbf')\n",
    "mapper.fit(train_embeddings)\n",
    "\n",
    "dump(mapper, 'PCA_400_v7_rbf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = load('PCA_400_v7_rbf.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedded = mapper.transform(train_embeddings)\n",
    "queries_embedded = mapper.transform(queries_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=16, metric='cosine', algorithm='brute')\n",
    "neigh.fit(train_embedded)\n",
    "\n",
    "distances, idxs = neigh.kneighbors(queries_embedded, 16, return_distance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = pd.DataFrame()\n",
    "pred_data['score'] = distances.flatten()\n",
    "pred_data['database_idx'] = [train_captions.index[x] for x in idxs.flatten()]\n",
    "pred_data.loc[:, 'query_idx'] = np.repeat(train_captions.index[1000:1300], 16).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data.score = pred_data.score.apply(lambda x: 1 - x)\n",
    "pred_data.score = (pred_data.score - pred_data.score.min(axis=0)) / (pred_data.score.max(axis=0) - pred_data.score.min(axis=0))\n",
    "pred_data.score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pymorphy2\n",
    "import razdel\n",
    "from string import punctuation\n",
    "\n",
    "nltk.download('stopwords') # скачиваем стоп-слова\n",
    "ru_stopwords = nltk.corpus.stopwords.words('russian')\n",
    "stop_words = ['...', 'cbn-быть', 'камаз-евро', 'верхний','высокий','г-образный','жёлтый','зелёный',\n",
    "              'красный','левый','синий','наружный','неподвижный','передний','п-образный','правый', 'т-смарт', 'т-flex',\n",
    "             'уралец', 'маз', 'камаз', 'медный', 'металлический', 'люкс', 'лобовой', 'коммунальный', 'вс-т', 'влево', 'вправо',\n",
    "             'задний', 'передний', 'ведущий', 'ведомый', 'болгария', 'греция', 'боковой', 'кабинный', 'азотировать', 'аналог',\n",
    "             'замедлительный', 'ямз', 'мом', 'торможение', 'прямой', 'простой', 'проходной', 'синтая', 'призматический', \n",
    "             'тупой', 'упираться', 'самоустанавливаться', 'радиальный', 'шариковый', 'плунжерный', 'подъёмный', 'трактор',\n",
    "             'раструбный', 'раструструбный', 'подвижный', 'русич', 'мпа', 'торцевой', 'лодочный', 'четверной', 'универсальный',\n",
    "             'ход', 'оцинк', 'стопорный', 'круглый', 'сечение', 'квадрат', 'цвет', 'накал', 'нижний', 'верхний', 'солнечный',\n",
    "             'конический', 'файтереть', 'номерной', 'рубашка', 'сцепление', 'давление', 'поворотный', 'рулевой', 'гладкий', \n",
    "             'сталь', 'нержавеющий', 'поворот', 'меш', 'всасывать', 'червячный', 'регулировочный', 'сельскохозяйственный', \n",
    "             'пку', 'профильный', 'повышать', 'понижать', 'шаровыя', 'распределительный', 'промежуточный', 'первичный', \n",
    "             'бульдозерный', 'ротационный', 'проч', 'пенька', 'ниточный', 'впускной', 'закалённый', 'мотоблок', 'голый', 'клапанный',\n",
    "             'новый', 'капот', 'штанга', 'цифровой', 'стремянка', 'секция', 'электрический', 'тарелка', 'резьбовой', 'скаут',\n",
    "             'универсал', 'сменный', 'средний', 'подключение', 'площадка', 'наружний', 'продольный', 'модификация', 'сетка', \n",
    "             'стрельчатый', 'прерывание', 'непрерывный', 'ходовой', 'приводной', 'средний', 'реверсивный', 'соединительный',\n",
    "             'кпс', 'ксп', 'стык', 'отверстый', 'маслосъёмный', 'раздвижной', 'предохранительный', 'тарелка', 'тсн', 'подогрев',\n",
    "             'хранение', 'урал', 'охлаждать', 'полевой', 'уралец', 'сеновязальный', 'джутовый', 'внешний', 'стальной', 'грубый',\n",
    "             'система', 'ожлаждение', 'коса', 'напорный', 'дистанционный', 'крестовидный', 'гидравлический', 'дизельный',\n",
    "             'двойной', 'толщина', 'жечь', 'крестовина', 'имбусовый', 'байонетный', 'навесный', 'усиленный', 'разбрасывать',\n",
    "             'жсу', 'год', 'мех', 'большой', 'малый', 'резьба', 'переходной', 'бум', 'бумажный', 'маслоналивной', 'плоский',\n",
    "             'внешний', 'внешн', 'грубый', 'серия', 'распорный', 'стальной', 'бумага', 'подрулевой', 'внутренний', 'раздаточный',\n",
    "             'роликовый', 'квт', 'градус', 'бобина', 'тонкий', 'зил', 'линейный', 'прозрачный', 'короткий', 'форкамерный']\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def preproc(sentence):\n",
    "    if 'Втулка' in sentence:\n",
    "        sentence += ' Втулка'\n",
    "    if 'Пластина' in sentence:\n",
    "        sentence += ' Пластина'\n",
    "    tokens = [_.text.lower() for _ in list(razdel.tokenize(str(sentence)))]\n",
    "    unique_tokens = set()\n",
    "\n",
    "    final_sentence = []\n",
    "\n",
    "    for token in tokens:\n",
    "        if (len(token) > 2 and not any([char.isdigit() for char in token])):\n",
    "            parsed_token = morph.parse(token)[0]\n",
    "            if str(parsed_token.tag) != 'LATN' \\\n",
    "            and parsed_token.normal_form not in ru_stopwords and parsed_token.normal_form not in punctuation \\\n",
    "            and parsed_token.normal_form not in stop_words:\n",
    "                \n",
    "                token = str(parsed_token.normal_form)\n",
    "                if token in ['u-болт', 'болт-скоба']:\n",
    "                    token = 'болт'\n",
    "                elif token == 'гидробак':\n",
    "                    token = 'бак'\n",
    "                elif token == 'полуось':\n",
    "                    token = 'ось'\n",
    "                elif token == 'проводы':\n",
    "                    token = 'провод'\n",
    "                elif token == 'фильтровать':\n",
    "                    token = 'фильтр'\n",
    "                elif 'пресс' in token:\n",
    "                    token = 'пресс'\n",
    "                elif 'хладон' in token:\n",
    "                    token = 'баллон'\n",
    "                elif 'поршневой' in token:\n",
    "                    token = 'поршень'\n",
    "                elif 'гайка' in token:\n",
    "                    token = 'гайка'\n",
    "                elif 'фреон' in token:\n",
    "                    token = 'газ'\n",
    "                elif 'трактор' in token:\n",
    "                    token = 'трактор'\n",
    "                elif 'датчик' in token:\n",
    "                    token = 'датчик'\n",
    "                elif 'ремкомплект' in token:\n",
    "                    token = 'ремень'\n",
    "                elif 'упак' in token:\n",
    "                    token = 'упаковка'\n",
    "                elif 'переходный' in token:\n",
    "                    token = 'переходник'\n",
    "                elif 'упл' in token:\n",
    "                    token = 'уплотнитель'\n",
    "                elif 'компл' in token:\n",
    "                    token = 'комплект'\n",
    "                elif 'стартер' in token:\n",
    "                    token = 'стартер'\n",
    "                elif 'шатунно-поршневой' in token:\n",
    "                    token = 'шатун'\n",
    "                elif 'форсунка-распылитель' in token:\n",
    "                    token = 'форсунка'\n",
    "                elif 'фиттинг' in token:\n",
    "                    token = 'фитинг'\n",
    "                elif 'всасывать' in token:\n",
    "                    token = 'вентилятор'\n",
    "                elif 'валик' in token:\n",
    "                    token = 'вал'\n",
    "                elif 'агретирование' in token:\n",
    "                    token = 'навеска'\n",
    "                elif 'агрегатирование' in token:\n",
    "                    token = 'навеска'\n",
    "                elif 'гидронасос' in token:\n",
    "                    token = 'гидравлический насос'\n",
    "                elif 'шарикоподшипник' in token:\n",
    "                    token = 'подшипник'\n",
    "                elif 'ролик-натяжитель' in token:\n",
    "                    token = 'ролик натяжитель'\n",
    "                    \n",
    "                if token not in unique_tokens:\n",
    "                    final_sentence.append(token)\n",
    "                    unique_tokens.add(token)\n",
    "    if not final_sentence:\n",
    "        final_sentence = ['другое']\n",
    "    return final_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas() # чтобы отображалось время применения функции\n",
    "\n",
    "%time train_captions['item_nm'] = train_captions['item_nm'].progress_apply(preproc)\n",
    "train_captions['item_nm'] = train_captions['item_nm'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pred_data.groupby(by='query_idx').apply(lambda dft: dft.nlargest(1, 'score')) \\\n",
    ".merge(train_captions, left_on='database_idx', right_on='idx')\n",
    "submit.drop(['score', 'idx', 'database_idx'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pred_data.merge(submit, how='left', on='query_idx')\n",
    "submit = submit.rename({'item_nm': 'key'}, axis=1)\n",
    "submit = submit.merge(train_captions, left_on='database_idx', right_on='idx').drop(['idx'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['marker'] = submit.apply(lambda x: str(x.key) in str(x.item_nm), axis=1)\n",
    "submit['score_2'] = submit.apply(lambda x: (x.score + x.marker) / 2 if x.marker else x.score / 2, axis=1)\n",
    "submit.drop(['item_nm', 'key', 'marker', 'score'], inplace=True, axis=1)\n",
    "submit = submit.sort_values(['query_idx', 'score_2'], ascending=[True, False]).reset_index(drop=True)\n",
    "submit = submit.rename({'score_2': 'score'}, axis=1)\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cv2.imread(f'data/train/1299.png').astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "image_idx = submit[submit.query_idx == 1299].database_idx.values\n",
    "\n",
    "for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(cv2.imread(f'data/train/{image_idx[i]}.png'))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}